{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9771e1e-2322-4640-8f3d-7b0117293dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray.x.chen123/Documents/research/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached data mappings...\n",
      "Loading Interactions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading interactions: 701528line [00:02, 344268.15line/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Users: 631986\n",
      "Total Items: 112565\n",
      "Total Interactions: 701528\n",
      "Loading Item Metadata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading item metadata: 112590line [00:00, 167269.42line/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cached.\n",
      "Encoding Item Titles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Item title embeddings: 100%|██████████| 112565/112565 [26:37<00:00, 70.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating User Review Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User review embeddings: 100%|██████████| 631986/631986 [2:26:42<00:00, 71.79it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings cached.\n",
      "Computing SVD latent factors for items...\n",
      "SVD latent factors added. Dimension: 2000\n",
      "Features cached.\n",
      "Fold 1/5\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.04batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 20.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.955543  3.7649174 4.893451  ... 1.2620151 5.137888  4.945681 ]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 1: Train Loss: 1.7153 | Val Loss: 0.3093 | Val MAE:0.5541 | Val RMSE: 0.9297\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.05batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.816468  3.5885997 4.64817   ... 1.7349715 4.9763184 4.8589597]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 2: Train Loss: 1.4503 | Val Loss: 0.3008 | Val MAE:0.5706 | Val RMSE: 0.9018\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.05batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.999124  4.286536  4.9519043 ... 1.9447325 5.0959206 4.8945594]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 3: Train Loss: 1.4158 | Val Loss: 0.3441 | Val MAE:0.5837 | Val RMSE: 1.0131\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.06batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.911625  2.5485356 4.7092085 ... 1.2520556 4.9519386 4.7782736]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 4: Train Loss: 1.3894 | Val Loss: 0.2887 | Val MAE:0.5395 | Val RMSE: 0.8915\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.03batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.930895  2.546204  4.6474004 ... 1.394331  5.0337043 4.851374 ]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 5: Train Loss: 1.3657 | Val Loss: 0.2780 | Val MAE:0.5285 | Val RMSE: 0.8668\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.04batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9707837 3.831585  4.7468524 ... 1.5616516 5.0746193 4.9240613]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 6: Train Loss: 1.3477 | Val Loss: 0.2785 | Val MAE:0.5218 | Val RMSE: 0.8761\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.06batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9082847 2.8354352 4.702272  ... 1.2775056 4.9698467 4.931593 ]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 7: Train Loss: 1.3352 | Val Loss: 0.2753 | Val MAE:0.5115 | Val RMSE: 0.8731\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.00batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 20.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9387875 3.8229792 4.730012  ... 1.3804493 5.052318  5.026682 ]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 8: Train Loss: 1.3183 | Val Loss: 0.2671 | Val MAE:0.5158 | Val RMSE: 0.8507\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:56<00:00,  4.85batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9833245 3.8936172 4.785772  ... 1.5529944 5.052036  4.9711294]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 9: Train Loss: 1.3048 | Val Loss: 0.2872 | Val MAE:0.5112 | Val RMSE: 0.9086\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:55<00:00,  4.96batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8349085 3.9707623 4.640236  ... 1.1872514 4.915089  4.787477 ]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 10: Train Loss: 1.2920 | Val Loss: 0.2595 | Val MAE:0.5032 | Val RMSE: 0.8559\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:55<00:00,  4.99batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9681396 4.135741  4.5304623 ... 1.1758865 5.056633  4.941602 ]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 11: Train Loss: 1.2787 | Val Loss: 0.2704 | Val MAE:0.5040 | Val RMSE: 0.8675\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.01batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.066119  3.074925  4.461817  ... 1.2649072 5.104216  5.063979 ]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 12: Train Loss: 1.2636 | Val Loss: 0.2679 | Val MAE:0.5084 | Val RMSE: 0.8613\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.02batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8425794 2.6166532 4.3860617 ... 1.2821496 4.97205   4.8727374]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 13: Train Loss: 1.2525 | Val Loss: 0.2748 | Val MAE:0.5291 | Val RMSE: 0.8692\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.02batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9787908 3.2819047 4.462974  ... 1.239338  5.069059  4.889463 ]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 14: Train Loss: 1.2382 | Val Loss: 0.2605 | Val MAE:0.5071 | Val RMSE: 0.8378\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.02batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0229635  2.7474217  4.5078616  ... 0.93238974 5.0712485  4.9784136 ]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Epoch 15: Train Loss: 1.2223 | Val Loss: 0.2971 | Val MAE:0.5253 | Val RMSE: 0.9289\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 20.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0229635  2.7474217  4.5078616  ... 0.93238974 5.0712485  4.9784136 ]\n",
      "[5. 3. 5. ... 1. 5. 5.]\n",
      "Fold 1 Final: MAE: 0.5253, RMSE: 0.9289\n",
      "Fold 2/5\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:54<00:00,  5.01batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 20.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.844799  4.9145412 4.767411  ... 4.918138  1.2729757 3.8364959]\n",
      "[5. 5. 5. ... 5. 1. 4.]\n",
      "Epoch 1: Train Loss: 1.7080 | Val Loss: 0.3262 | Val MAE:0.6148 | Val RMSE: 0.9332\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:55<00:00,  4.95batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 21.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.2154784 5.10436   4.9409213 ... 5.111803  1.16456   4.2900257]\n",
      "[5. 5. 5. ... 5. 1. 4.]\n",
      "Epoch 2: Train Loss: 1.4545 | Val Loss: 0.2994 | Val MAE:0.5373 | Val RMSE: 0.9227\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:56<00:00,  4.89batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 20.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.7165382 4.9361725 4.680546  ... 4.960857  1.2692426 3.763457 ]\n",
      "[5. 5. 5. ... 5. 1. 4.]\n",
      "Epoch 3: Train Loss: 1.4154 | Val Loss: 0.2848 | Val MAE:0.5433 | Val RMSE: 0.8729\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:56<00:00,  4.86batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 20.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.096775  5.016957  4.85748   ... 5.082095  1.3199866 4.2662296]\n",
      "[5. 5. 5. ... 5. 1. 4.]\n",
      "Epoch 4: Train Loss: 1.3877 | Val Loss: 0.2812 | Val MAE:0.5155 | Val RMSE: 0.8885\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:56<00:00,  4.88batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 20.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6428125 4.907384  4.691933  ... 4.936069  1.0946246 3.8731773]\n",
      "[5. 5. 5. ... 5. 1. 4.]\n",
      "Epoch 5: Train Loss: 1.3669 | Val Loss: 0.3033 | Val MAE:0.5616 | Val RMSE: 0.9124\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 275/275 [00:56<00:00,  4.84batch/s]\n",
      "Evaluating: 100%|██████████| 69/69 [00:03<00:00, 20.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.155861  5.1246815 4.9393806 ... 5.1910467 1.0759174 4.3416276]\n",
      "[5. 5. 5. ... 5. 1. 4.]\n",
      "Epoch 6: Train Loss: 1.3503 | Val Loss: 0.2886 | Val MAE:0.5232 | Val RMSE: 0.9073\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  80%|████████  | 220/275 [00:46<00:11,  4.65batch/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# For SVD on rating matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Fix for CUDA multiprocessing error:\n",
    "import torch.multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Configuration & Hyperparameters\n",
    "# ---------------------------------------------------------------------\n",
    "DATA_PATH_INTERACTIONS = \"./All_Beauty.jsonl\"\n",
    "DATA_PATH_ITEMS = \"./meta_All_Beauty.jsonl\"\n",
    "PRETRAINED_TEXT_MODEL = \"distilbert-base-uncased\"\n",
    "\n",
    "# The transformer model will fuse features into this hidden dimension.\n",
    "HIDDEN_DIM = 512  \n",
    "BATCH_SIZE = 2048\n",
    "LR = 1e-4\n",
    "EPOCHS = 15             # Increased epochs\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "SVD_COMPONENTS = 2000      # Number of SVD components\n",
    "\n",
    "LAMBDA_CLS = 1.5         # Classification loss weight\n",
    "# Cache directories\n",
    "os.makedirs(\"advanced_cache\", exist_ok=True)\n",
    "DATA_CACHE_PATH = \"advanced_cache/data.pkl\"\n",
    "EMBED_CACHE_PATH = \"advanced_cache/embeddings.pkl\"\n",
    "FEATURE_CACHE_PATH = \"advanced_cache/features.pkl\"\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Data Loading and Caching with JSON Error Handling\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"Loading cached data mappings...\")\n",
    "if os.path.exists(DATA_CACHE_PATH):\n",
    "    with open(DATA_CACHE_PATH, 'rb') as f:\n",
    "        data_cache = pickle.load(f)\n",
    "    user2id = data_cache[\"user2id\"]\n",
    "    item2id = data_cache[\"item2id\"]\n",
    "    interactions_list = data_cache[\"interactions_list\"]\n",
    "    item_metadata = data_cache[\"item_metadata\"]\n",
    "else:\n",
    "    user2id = {}\n",
    "    item2id = {}\n",
    "    interactions_list = []\n",
    "    print(\"Loading Interactions...\")\n",
    "    i = 0\n",
    "    with open(DATA_PATH_INTERACTIONS, 'r') as f:\n",
    "        for line in tqdm(f, desc=\"Reading interactions\", unit=\"line\"):\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipping line {i} due to JSONDecodeError: {e}\")\n",
    "                i += 1\n",
    "                continue\n",
    "            user_id = record.get(\"user_id\")\n",
    "            item_id = record.get(\"parent_asin\")\n",
    "            rating = record.get(\"rating\", None)\n",
    "            review_text = record.get(\"text\", \"\")\n",
    "            review_title = record.get(\"title\", \"\")\n",
    "            verified = record.get(\"verified_purchase\", False)\n",
    "            timestamp = record.get(\"timestamp\", None)\n",
    "            helpful_votes = record.get(\"helpful_votes\", 0)\n",
    "            if user_id not in user2id:\n",
    "                user2id[user_id] = len(user2id)\n",
    "            if item_id not in item2id:\n",
    "                item2id[item_id] = len(item2id)\n",
    "            interactions_list.append({\n",
    "                \"user_id\": user2id[user_id],\n",
    "                \"item_id\": item2id[item_id],\n",
    "                \"rating\": float(rating) if rating is not None else 0.0,\n",
    "                \"review_text\": review_text,\n",
    "                \"review_title\": review_title,\n",
    "                \"verified\": verified,\n",
    "                \"timestamp\": timestamp,\n",
    "                \"helpful_votes\": helpful_votes\n",
    "            })\n",
    "            i += 1\n",
    "    print(\"Total Users:\", len(user2id))\n",
    "    print(\"Total Items:\", len(item2id))\n",
    "    print(\"Total Interactions:\", len(interactions_list))\n",
    "    print(\"Loading Item Metadata...\")\n",
    "    item_metadata = [None] * len(item2id)\n",
    "    with open(DATA_PATH_ITEMS, 'r', encoding='utf-8') as f:\n",
    "        for j, line in enumerate(tqdm(f, desc=\"Reading item metadata\", unit=\"line\")):\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipping metadata line {j} due to JSONDecodeError: {e}\")\n",
    "                continue\n",
    "            parent_asin = record.get(\"parent_asin\")\n",
    "            if parent_asin not in item2id:\n",
    "                continue\n",
    "            idx = item2id[parent_asin]\n",
    "            title = record.get(\"title\", \"\")\n",
    "            avg_rating = record.get(\"average_rating\", 0.0)\n",
    "            rating_num = record.get(\"rating_number\", 0.0)\n",
    "            price = record.get(\"price\", 0.0)\n",
    "            item_metadata[idx] = {\n",
    "                \"title\": title,\n",
    "                \"avg_rating\": avg_rating,\n",
    "                \"rating_num\": rating_num,\n",
    "                \"price\": 0 if price is None else price\n",
    "            }\n",
    "    data_cache = {\n",
    "        \"user2id\": user2id,\n",
    "        \"item2id\": item2id,\n",
    "        \"interactions_list\": interactions_list,\n",
    "        \"item_metadata\": item_metadata\n",
    "    }\n",
    "    with open(DATA_CACHE_PATH, 'wb') as f:\n",
    "        pickle.dump(data_cache, f)\n",
    "    print(\"Data cached.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Text Embeddings Using Pretrained Transformer (BERT)\n",
    "# ---------------------------------------------------------------------\n",
    "if os.path.exists(EMBED_CACHE_PATH):\n",
    "    with open(EMBED_CACHE_PATH, 'rb') as f:\n",
    "        embed_cache = pickle.load(f)\n",
    "    user_text_embeds = embed_cache[\"user_text_embeds\"]\n",
    "    item_text_embeds = embed_cache[\"item_text_embeds\"]\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_TEXT_MODEL)\n",
    "    text_model = AutoModel.from_pretrained(PRETRAINED_TEXT_MODEL).to(device)\n",
    "    text_model.eval()\n",
    "    @torch.no_grad()\n",
    "    def encode_texts(texts, max_length=64):\n",
    "        if len(texts) == 0:\n",
    "            return torch.zeros(text_model.config.hidden_size)\n",
    "        inputs = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt').to(device)\n",
    "        outputs = text_model(**inputs)\n",
    "        cls_embeds = outputs.last_hidden_state[:, 0, :]\n",
    "        return cls_embeds.mean(dim=0).cpu()\n",
    "    print(\"Encoding Item Titles...\")\n",
    "    item_text_embeds = torch.zeros((len(item2id), text_model.config.hidden_size))\n",
    "    for i in tqdm(range(len(item2id)), desc=\"Item title embeddings\"):\n",
    "        meta = item_metadata[i]\n",
    "        if meta is None:\n",
    "            emb = torch.zeros(text_model.config.hidden_size)\n",
    "        else:\n",
    "            emb = encode_texts([meta[\"title\"]])\n",
    "        item_text_embeds[i] = emb\n",
    "    print(\"Aggregating User Review Embeddings...\")\n",
    "    user_reviews_map = {uid: [] for uid in range(len(user2id))}\n",
    "    for inter in interactions_list:\n",
    "        uid = inter[\"user_id\"]\n",
    "        user_reviews_map[uid].append(inter[\"review_text\"])\n",
    "    user_text_embeds = torch.zeros((len(user2id), text_model.config.hidden_size))\n",
    "    for uid in tqdm(user_reviews_map.keys(), desc=\"User review embeddings\"):\n",
    "        revs = user_reviews_map[uid]\n",
    "        sampled_revs = revs[:5]\n",
    "        if sampled_revs:\n",
    "            emb = encode_texts(sampled_revs)\n",
    "        else:\n",
    "            emb = torch.zeros(text_model.config.hidden_size)\n",
    "        user_text_embeds[uid] = emb\n",
    "    embed_cache = {\n",
    "        \"user_text_embeds\": user_text_embeds,\n",
    "        \"item_text_embeds\": item_text_embeds\n",
    "    }\n",
    "    with open(EMBED_CACHE_PATH, 'wb') as f:\n",
    "        pickle.dump(embed_cache, f)\n",
    "    print(\"Embeddings cached.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Feature Engineering: Multi-Modal Item Features & User Features\n",
    "# ---------------------------------------------------------------------\n",
    "if os.path.exists(FEATURE_CACHE_PATH):\n",
    "    with open(FEATURE_CACHE_PATH, 'rb') as f:\n",
    "        feature_cache = pickle.load(f)\n",
    "    user_features = feature_cache[\"user_features\"]      # shape: (num_users, text_dim)\n",
    "    item_text_features = feature_cache[\"item_text_features\"]  # shape: (num_items, text_dim)\n",
    "    item_numeric_features = feature_cache[\"item_numeric_features\"]  # shape: (num_items, 3)\n",
    "    item_svd_features = feature_cache[\"item_svd_features\"]  # shape: (num_items, SVD_COMPONENTS)\n",
    "else:\n",
    "    for i, meta in enumerate(item_metadata):\n",
    "        if meta is None:\n",
    "            item_metadata[i] = {\"avg_rating\": 0.0, \"rating_num\": 0.0, \"price\": 0.0, \"title\":\"\"}\n",
    "    item_avg_ratings = torch.tensor([m[\"avg_rating\"] for m in item_metadata], dtype=torch.float32)\n",
    "    item_rating_counts = torch.tensor([m[\"rating_num\"] for m in item_metadata], dtype=torch.float32)\n",
    "    item_prices = torch.tensor([m[\"price\"] for m in item_metadata], dtype=torch.float32)\n",
    "    item_avg_ratings = (item_avg_ratings - item_avg_ratings.mean()) / (item_avg_ratings.std() + 1e-9)\n",
    "    item_rating_counts = (item_rating_counts - item_rating_counts.mean()) / (item_rating_counts.std() + 1e-9)\n",
    "    item_prices = (item_prices - item_prices.mean()) / (item_prices.std() + 1e-9)\n",
    "    item_numeric_features = torch.cat([\n",
    "        item_avg_ratings.unsqueeze(-1),\n",
    "        item_rating_counts.unsqueeze(-1),\n",
    "        item_prices.unsqueeze(-1)\n",
    "    ], dim=-1)\n",
    "    print(\"Computing SVD latent factors for items...\")\n",
    "    num_items = len(item2id)\n",
    "    num_users = len(user2id)\n",
    "    rows, cols, data_vals = [], [], []\n",
    "    for inter in interactions_list:\n",
    "        rows.append(inter[\"item_id\"])\n",
    "        cols.append(inter[\"user_id\"])\n",
    "        data_vals.append(inter[\"rating\"])\n",
    "    rating_matrix = coo_matrix((data_vals, (rows, cols)), shape=(num_items, num_users))\n",
    "    svd = TruncatedSVD(n_components=SVD_COMPONENTS, random_state=42)\n",
    "    svd_features = svd.fit_transform(rating_matrix)\n",
    "    item_svd_features = torch.tensor(svd_features, dtype=torch.float32)\n",
    "    print(\"SVD latent factors added. Dimension:\", item_svd_features.size(1))\n",
    "    item_text_features = item_text_embeds\n",
    "    user_features = user_text_embeds\n",
    "    feature_cache = {\n",
    "        \"user_features\": user_features,\n",
    "        \"item_text_features\": item_text_features,\n",
    "        \"item_numeric_features\": item_numeric_features,\n",
    "        \"item_svd_features\": item_svd_features\n",
    "    }\n",
    "    with open(FEATURE_CACHE_PATH, 'wb') as f:\n",
    "        pickle.dump(feature_cache, f)\n",
    "    print(\"Features cached.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Create Fused Item Features by Concatenating Modalities\n",
    "# ---------------------------------------------------------------------\n",
    "# For each item, we concatenate text features, numeric features, and SVD features.\n",
    "# The resulting item feature dimension is: text_dim + 3 + SVD_COMPONENTS.\n",
    "text_dim = item_text_features.shape[1]\n",
    "item_features = torch.cat([item_text_features, item_numeric_features, item_svd_features], dim=-1)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Define a PyTorch Dataset for Interactions\n",
    "# ---------------------------------------------------------------------\n",
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, interactions, user_features, item_features):\n",
    "        self.interactions = interactions\n",
    "        self.user_features = user_features  # shape: (num_users, text_dim)\n",
    "        self.item_features = item_features  # shape: (num_items, text_dim + 3 + SVD_COMPONENTS)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.interactions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inter = self.interactions[idx]\n",
    "        user_id = inter[\"user_id\"]\n",
    "        item_id = inter[\"item_id\"]\n",
    "        rating = inter[\"rating\"]\n",
    "        user_feat = self.user_features[user_id]\n",
    "        item_feat = self.item_features[item_id]\n",
    "        # For classification, the target class is rating-1 (assuming ratings in {1,2,3,4,5})\n",
    "        target_cls = int(rating) - 1 if rating >= 1 else 0\n",
    "        return user_feat, item_feat, rating, target_cls\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Transformer Fusion Recommender Model\n",
    "# ---------------------------------------------------------------------\n",
    "class TransformerFusionRecommender(nn.Module):\n",
    "    def __init__(self, user_dim, item_dim, hidden_dim, num_layers=2, num_heads=4, num_classes=5):\n",
    "        super().__init__()\n",
    "        # Project input features to hidden_dim\n",
    "        self.user_proj = nn.Linear(user_dim, hidden_dim)\n",
    "        self.item_proj = nn.Linear(item_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, batch_first=True)\n",
    "        self.user_transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.item_transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # Cross-attention: user queries attend to item representation\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.fusion_linear = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, user_feat, item_feat):\n",
    "        # user_feat: (batch, user_dim), item_feat: (batch, item_dim)\n",
    "        user_h = self.user_proj(user_feat)   # (batch, hidden_dim)\n",
    "        item_h = self.item_proj(item_feat)   # (batch, hidden_dim)\n",
    "        # Add dummy sequence dimension\n",
    "        user_h = user_h.unsqueeze(1)  # (batch, 1, hidden_dim)\n",
    "        item_h = item_h.unsqueeze(1)  # (batch, 1, hidden_dim)\n",
    "        user_enc = self.user_transformer(user_h)  # (batch, 1, hidden_dim)\n",
    "        item_enc = self.item_transformer(item_h)  # (batch, 1, hidden_dim)\n",
    "        # Cross-attention: use user_enc as query, item_enc as key/value\n",
    "        cross_out, _ = self.cross_attn(query=user_enc, key=item_enc, value=item_enc)\n",
    "        # Squeeze sequence dimension\n",
    "        user_enc = user_enc.squeeze(1)\n",
    "        cross_out = cross_out.squeeze(1)\n",
    "        fused = self.fusion_linear(torch.cat([user_enc, cross_out], dim=-1))\n",
    "        reg_out = self.regressor(fused).squeeze(-1)\n",
    "        cls_logits = self.classifier(fused)\n",
    "        return reg_out, cls_logits\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Training and Evaluation Functions for the New Model\n",
    "# ---------------------------------------------------------------------\n",
    "def train_epoch_transformer(model, optimizer, dataloader, criterion_reg, criterion_cls):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for user_feat, item_feat, target_reg, target_cls in tqdm(dataloader, desc=\"Training epoch\", unit=\"batch\"):\n",
    "        user_feat = user_feat.to(device)\n",
    "        item_feat = item_feat.to(device)\n",
    "        target_reg = target_reg.to(device)\n",
    "        target_cls = target_cls.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        reg_pred, cls_logits = model(user_feat, item_feat)\n",
    "        loss_reg = criterion_reg(reg_pred, target_reg)\n",
    "        loss_cls = criterion_cls(cls_logits, target_cls)\n",
    "        loss = loss_reg + LAMBDA_CLS * loss_cls\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * user_feat.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_transformer(model, dataloader, criterion_reg, criterion_cls):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for user_feat, item_feat, target_reg, target_cls in tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "        user_feat = user_feat.to(device)\n",
    "        item_feat = item_feat.to(device)\n",
    "        target_reg = target_reg.to(device)\n",
    "        reg_pred, cls_logits = model(user_feat, item_feat)\n",
    "        loss_reg = criterion_reg(reg_pred, target_reg)\n",
    "        total_loss += loss_reg.item() * user_feat.size(0)\n",
    "        preds.append(reg_pred.detach().cpu().numpy())\n",
    "        targets.append(target_reg.detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    print(preds)\n",
    "    print(targets)\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    rmse = root_mean_squared_error(targets, preds)\n",
    "    return mae, rmse, total_loss / len(dataloader.dataset)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Main Training Loop with Cross-Validation for the Transformer Model\n",
    "# ---------------------------------------------------------------------\n",
    "# Prepare complete item features and user features (precomputed)\n",
    "user_feats = user_features  # shape: (num_users, text_dim)\n",
    "# For items, use our concatenated features\n",
    "item_feats = item_features  # shape: (num_items, text_dim + 3 + SVD_COMPONENTS)\n",
    "\n",
    "# Create a list of interaction indices for cross-validation\n",
    "all_indices = np.arange(len(interactions_list))\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "all_mae = []\n",
    "all_rmse = []\n",
    "\n",
    "criterion_reg = nn.SmoothL1Loss()  # Huber loss\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(all_indices)):\n",
    "    print(f\"Fold {fold+1}/{NUM_FOLDS}\")\n",
    "    train_inter = [interactions_list[i] for i in train_idx]\n",
    "    test_inter = [interactions_list[i] for i in test_idx]\n",
    "    \n",
    "    train_dataset = InteractionDataset(train_inter, user_feats, item_feats)\n",
    "    test_dataset = InteractionDataset(test_inter, user_feats, item_feats)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Define dimensions for the transformer model:\n",
    "    user_dim = user_feats.shape[1]          # e.g. text_dim from BERT\n",
    "    item_dim = item_feats.shape[1]          # text_dim + 3 + SVD_COMPONENTS\n",
    "    model = TransformerFusionRecommender(user_dim, item_dim, hidden_dim=HIDDEN_DIM,\n",
    "                                          num_layers=2, num_heads=4).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    best_val_mae = float('inf')\n",
    "    early_stop_patience = 5\n",
    "    no_improve_epochs = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        train_loss = train_epoch_transformer(model, optimizer, train_loader, criterion_reg, criterion_cls)\n",
    "        val_mae, val_rmse, val_loss = evaluate_transformer(model, test_loader, criterion_reg, criterion_cls)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val MAE:{val_mae:.4f} | Val RMSE: {val_rmse:.4f}\")\n",
    "        if val_mae < best_val_mae:\n",
    "            best_val_mae = val_mae\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= early_stop_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    fold_mae, fold_rmse, _ = evaluate_transformer(model, test_loader, criterion_reg, criterion_cls)\n",
    "    print(f\"Fold {fold+1} Final: MAE: {fold_mae:.4f}, RMSE: {fold_rmse:.4f}\")\n",
    "    all_mae.append(fold_mae)\n",
    "    all_rmse.append(fold_rmse)\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(\"MAE per fold:\", all_mae)\n",
    "print(\"RMSE per fold:\", all_rmse)\n",
    "print(\"Mean MAE:\", np.nanmean(all_mae), \"Mean RMSE:\", np.nanmean(all_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0363b-5ea3-43ab-9213-8cd46de1c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross-Validation Results:\n",
    "MAE per fold: [0.49213757361534505, 0.5203920227670602, 0.5501907572041689, 0.5028691199894604, 0.5111886623057732]\n",
    "RMSE per fold: [0.8844305602048712, 0.9108551409362662, 0.9460393990431739, 0.8631044222211626, 0.8369910783816911]\n",
    "Mean MAE: 0.5153556271763615 Mean RMSE: 0.888284120157433"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
